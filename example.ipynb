{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c63077-aab8-4373-9727-0e27c43b40cd",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdea1bf2-19d2-4eaa-90cb-2448834ce07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard packages\n",
    "import sys\n",
    "# When installing new packages uncomment the following line:\n",
    "# !{sys.executable} -m pip install shap\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# SHAP\n",
    "import shap\n",
    "\n",
    "#Plotting\n",
    "import seaborn as sns\n",
    "sns.set_style()\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "# Silence\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "\n",
    "# Timing \n",
    "from time import perf_counter\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d402934-4d44-4943-afbe-d7bc5634b293",
   "metadata": {},
   "source": [
    "# Set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcacf921-068e-422e-992d-fca5dc2c9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefiles=False\n",
    "basis='cc-PVDZ'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c83d9-4581-46b4-8780-6374c8418e9e",
   "metadata": {},
   "source": [
    "# Functions to help generate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a862b-82eb-456a-afa1-cbc2cb48a7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_df(path):\n",
    "    '''\n",
    "    Function to generate data from path\n",
    "    \n",
    "    returns Pandas dataframe\n",
    "    '''\n",
    "    radius=float(re.findall(\"\\d+\\.\\d+\", os.path.basename(os.path.normpath(path)).split('_')[-1].split()[0])[0])\n",
    "    data=[]\n",
    "    mat_keys=[]\n",
    "    with open(path,'r') as f:\n",
    "        # Read file\n",
    "        FILE = f.readlines()\n",
    "\n",
    "        # Grab easy features\n",
    "        for idx,i in enumerate(FILE):\n",
    "            if len(i.split())!=0:\n",
    "                fltfinder=re.findall('-?\\d+\\.?\\d*', i.split()[-1])\n",
    "                if '==> v2RDM' in i and 'Violation' not in i:\n",
    "                    mat_keys.append((idx,''.join(i.split()[1:3])))\n",
    "                if len(fltfinder)==1:\n",
    "                    flt=float(fltfinder[0])\n",
    "                    if 'DETCI' in i or 'HF' in i:\n",
    "                        data.append(('DETCI@energy', flt))\n",
    "                    if 'v2RDM' in i:\n",
    "                        data.append((''.join(i.split()[0:2]),flt))\n",
    "\n",
    "        og_data = dict(data)            \n",
    "        # Dictionary with keys and indices for the matrices     \n",
    "        mat_dict=dict(mat_keys)   \n",
    "\n",
    "        result = {}\n",
    "\n",
    "        for key,value in mat_dict.items():\n",
    "            if value not in result.values():\n",
    "                result[key] = value\n",
    "\n",
    "        mat_dict=result\n",
    "\n",
    "    return pd.DataFrame.from_dict(og_data,orient='index',columns=[radius])    \n",
    "\n",
    "def collate_data(paths):\n",
    "    '''\n",
    "    Create a Pandas dataframe from all the available data\n",
    "    '''\n",
    "    cd = pd.concat([gen_df(i) for i in paths],axis=1).sort_index(axis=1)\n",
    "    return cd.T.loc[:,~cd.T.columns.duplicated()].T\n",
    "\n",
    "def Energies(data):\n",
    "    '''\n",
    "    Collate dataframe\n",
    "    '''\n",
    "    cd=collate_data(data)\n",
    "    return cd.loc['DETCI@energy'],cd.loc['v2RDM@energy']\n",
    "\n",
    "def genXy(data):\n",
    "    ''' \n",
    "    Seperate targets (y) from features (X)\n",
    "    '''\n",
    "    cd=collate_data(data)\n",
    "    \n",
    "    y=cd.loc['DETCI@energy']-cd.loc['v2RDM@energy']\n",
    "    X=cd.drop(['DETCI@energy','v2RDM@energy','v2RDM@Nalpha','v2RDM@Nbeta','v2RDM@Nact','v2RDM@S2']).T\n",
    "                \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262528c4-46e5-4d7c-a539-03938cc8557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the data is partitioned\n",
    "systems=sorted([i.split('/')[-1] for i in glob('./singlet_doublet/*/*')])\n",
    "spins=['singlet_doublet','triplet_quartet']\n",
    "basissets=['STO-3G','6-31G','cc-PVDZ']\n",
    "\n",
    "# Grab spins\n",
    "s2_dict={sp:{sy:{bs:gen_df(glob(f'./{sp}/v2rdm_ontop_fci_eval_t1t2/{sy}/{bs}/*')[0]).loc['v2RDM@S2'].to_numpy() for bs in basissets} for sy in systems} for sp in spins}\n",
    "\n",
    "# \n",
    "groundstates=[]\n",
    "excitedstates=[]\n",
    "for system in systems:\n",
    "    for basis in basissets:\n",
    "        sd_DETCI_E,sd_v2RDM_E=Energies(glob(f'./{spins[0]}/v2rdm_ontop_fci_eval_t1t2/{system}/{basis}/*'))\n",
    "        tq_DETCI_E,tq_v2RDM_E=Energies(glob(f'./{spins[1]}/v2rdm_ontop_fci_eval_t1t2/{system}/{basis}/*'))\n",
    "        if sd_DETCI_E.min()<tq_DETCI_E.min():\n",
    "            # print(system,basis,sd_DETCI_E.min(),tq_DETCI_E.min())\n",
    "            groundstates.append(('singlet_doublet',system,basis))\n",
    "            excitedstates.append(('triplet_quartet',system,basis))\n",
    "        else:\n",
    "            groundstates.append(('triplet_quartet',system,basis))\n",
    "            excitedstates.append(('singlet_doublet',system,basis))\n",
    "            \n",
    "\n",
    "# Choose your basis set, this example uses cc-PVDZ            \n",
    "rads=[]\n",
    "\n",
    "for st,sy,bs in tqdm(groundstates+excitedstates, desc='Data', position=0, leave=True):\n",
    "    if bs==basis:\n",
    "        rads.append((sy+'_'+st,genXy(glob(f'./{st}/v2rdm_ontop_fci_eval_t1t2/{sy}/{bs}/*'))))\n",
    "    \n",
    "system_dict=dict(rads)       \n",
    "\n",
    "\n",
    "# Remove data based on violations\n",
    "violations=['v2RDM@RMSViolation(T1)','v2RDM@RMSViolation(T2)']\n",
    "popped={}\n",
    "for k,v in system_dict.copy().items():\n",
    "    if any(v[0][violations].mean()<=1e-6):\n",
    "        popped[k]=v\n",
    "        del system_dict[k]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063df72e-01a1-4640-93db-96377e2a4ab0",
   "metadata": {},
   "source": [
    "# Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78707ffd-ae9b-4c08-8b87-47dfa571c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and testing \n",
    "key_train={}\n",
    "key_test={}\n",
    "X_train=[]\n",
    "y_train=[]\n",
    "\n",
    "X_test=[]\n",
    "y_test=[]\n",
    "\n",
    "\n",
    "for k,(X,y) in system_dict.items():\n",
    "    train,test=list(y.index[0::2]),list(y.index[1::2])\n",
    "    key_train[k]=train\n",
    "    key_test[k]=test    \n",
    "    X_train.append(X.loc[train])\n",
    "    y_train.append(pd.DataFrame(y.loc[train]).rename(columns={0:k}))\n",
    "    X_test.append(X.loc[test])\n",
    "    y_test.append(pd.DataFrame(y.loc[test]).rename(columns={0:k}))\n",
    "    \n",
    "X_train=pd.concat(X_train)\n",
    "ytraindf=pd.concat(y_train,axis=1)\n",
    "\n",
    "X_test=pd.concat(X_test)\n",
    "ytestdf=pd.concat(y_test,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainidx=X_train.index\n",
    "traincol=X_train.columns\n",
    "\n",
    "testidx=X_test.index\n",
    "testcol=X_test.columns\n",
    "\n",
    "y_train=ytraindf\n",
    "y_test=ytestdf\n",
    "\n",
    "# Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_train = y_train.T.stack().to_numpy()\n",
    "y_test = y_test.T.stack().to_numpy()\n",
    "\n",
    "X_train = pd.DataFrame(X_train,index=trainidx,columns=traincol)\n",
    "X_test = pd.DataFrame(X_test,index=testidx,columns=testcol)\n",
    "\n",
    "\n",
    "# Find optimal hyperparameters for KRR\n",
    "parameters = {'kernel': ['rbf'],'alpha':np.logspace(-6,6,7),'gamma':np.logspace(-6,6,7)}\n",
    "GridSearch = GridSearchCV(KernelRidge(),param_grid=parameters,cv=5,verbose=0).fit(X_train,y_train)\n",
    "model=GridSearch.best_estimator_.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predicted values\n",
    "train_pred=model.predict(X_train)\n",
    "test_pred=model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "stats={'Train':len(train),\n",
    "       'Test':len(test),\n",
    "       'Train MAPE':mean_absolute_percentage_error(y_train,train_pred)*100,\n",
    "       'Test MAPE':mean_absolute_percentage_error(y_test,test_pred)*100,\n",
    "       'Train R2':r2_score(y_train,train_pred),\n",
    "       'Test R2':r2_score(y_test,test_pred),\n",
    "       'Train MAE':mean_absolute_error(y_train,train_pred),\n",
    "       'Test MAE':mean_absolute_error(y_test,test_pred),\n",
    "       'Train RMSE':mean_squared_error(y_train,train_pred, squared=False),\n",
    "       'Test RMSE':mean_squared_error(y_test,test_pred, squared=False)}\n",
    "\n",
    "df_stats=pd.DataFrame.from_dict(stats,orient='index')\n",
    "\n",
    "\n",
    "if savefiles==True:\n",
    "    df_stats.rename(columns={0:'Stats'}).to_excel(f'{basis}_bigstackstats.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1cfdb-895e-43b9-9b53-8c23f86e3a92",
   "metadata": {},
   "source": [
    "# Machine Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a7666-f545-45fc-a451-b2ada764a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting colors\n",
    "colormap=sns.color_palette('rocket',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc768b4-40c5-4653-b354-669a2d90bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A collection of data used for plotting\n",
    "# GS-ground state\n",
    "# ES-excited state\n",
    "Y=pd.concat([pd.DataFrame(y,columns=[k]) for k,(X,y) in system_dict.items()],axis=1)\n",
    "ytrain_preddf=pd.DataFrame(train_pred,index=ytraindf.T.stack().index).unstack().T.droplevel(0)\n",
    "ytest_preddf=pd.DataFrame(test_pred,index=ytestdf.T.stack().index).unstack().T.droplevel(0)\n",
    "\n",
    "GS_df=pd.concat([Y[f'{nam}_{st}'] for (st,nam,bs) in groundstates if bs==basis and f'{nam}_{st}' in Y.columns],axis=1)\n",
    "ES_df=pd.concat([Y[f'{nam}_{st}'] for (st,nam,bs) in excitedstates if bs==basis and f'{nam}_{st}' in Y.columns],axis=1)\n",
    "all_df=pd.concat([GS_df,ES_df],axis=1).sort_index(axis=1)\n",
    "\n",
    "# Reformat the data\n",
    "GS_ytrain_df=ytraindf[GS_df.columns]\n",
    "ES_ytrain_df=ytraindf[ES_df.columns]\n",
    "GS_ytrain_preddf=ytrain_preddf[GS_df.columns]\n",
    "ES_ytrain_preddf=ytrain_preddf[ES_df.columns]\n",
    "\n",
    "GS_ytest_df=ytestdf[GS_df.columns]\n",
    "ES_ytest_df=ytestdf[ES_df.columns]\n",
    "GS_ytest_preddf=ytest_preddf[GS_df.columns]\n",
    "ES_ytest_preddf=ytest_preddf[ES_df.columns]\n",
    "\n",
    "# The calculated energies\n",
    "GS_energies={nam:dict(zip(['FCI','v2RDM'],Energies(glob(f'./{st}/v2rdm_ontop_fci_eval_t1t2/{nam}/{bs}/*')))) for (st,nam,bs) in groundstates if bs==basis}\n",
    "ES_energies={nam:dict(zip(['FCI','v2RDM'],Energies(glob(f'./{st}/v2rdm_ontop_fci_eval_t1t2/{nam}/{bs}/*')))) for (st,nam,bs) in excitedstates if bs==basis}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72131d3-8c5c-401e-88f3-e582585d1dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot machine learning results versus the v2RDM and FCI error... FCI error is 0\n",
    "fontsize = 10\n",
    "plt.rcParams.update({'font.size': fontsize})\n",
    "plt.rc('font', size=fontsize)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=fontsize)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=fontsize)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=fontsize)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=fontsize)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=fontsize)    # legend fontsize\n",
    "plt.rc('figure', titlesize=fontsize)  # fontsize of the figure title\n",
    "\n",
    "for idx,nam in enumerate(GS_df.columns):\n",
    "    fig,ax=plt.subplots(1,2,figsize=(10,5),sharey=True,sharex=True)\n",
    "    if 'triplet_quartet' in nam:\n",
    "        i=nam.replace('_triplet_quartet','')\n",
    "    if 'singlet_doublet' in nam:\n",
    "        i=nam.replace('_singlet_doublet','')\n",
    "        \n",
    "    GS_CI,GS_rdm=GS_energies[i]['FCI'],GS_energies[i]['v2RDM']\n",
    "    ES_CI,ES_rdm=ES_energies[i]['FCI'],ES_energies[i]['v2RDM']\n",
    "\n",
    "    for j in list(GS_df.columns):\n",
    "        if f'{i}_' in j:\n",
    "            train=key_train[j]\n",
    "            test=key_test[j]\n",
    "            \n",
    "            ax[0].plot(GS_df[j],'k--',label='E$_{CI}$-E$_{v2RDM}$')\n",
    "            ax[0].plot(range(len(GS_df[j])),len(GS_df[j])*[0],'k-')\n",
    "            ax[0].plot(GS_CI.loc[train]-(GS_ytrain_preddf[j]+GS_rdm.loc[train]),'o',color=colormap[0],label='E$_{CI}$-E$_{DDv2RDM}$ (Train)')\n",
    "            ax[0].plot(GS_CI.loc[test]-(GS_ytest_preddf[j]+GS_rdm.loc[test]),'x',color=colormap[0],label='E$_{CI}$-E$_{DDv2RDM}$ (Test)')\n",
    "            \n",
    "            ax[0].set_xlim(.5,3)\n",
    "            ax[0].set_ylim(-0.01,0.15)\n",
    "            ax[0].legend(loc=2)\n",
    "            ax[0].set_ylabel('Deviation (E$_{h}$)')\n",
    "            ax[0].set_title(f'{i} Ground Spin State')\n",
    "            ax[0].set_xlabel('Bond Length (Å)')            \n",
    "\n",
    "    for j in list(ES_df.columns):\n",
    "        if f'{i}_' in j:     \n",
    "            print(i,nam,j)\n",
    "            train=key_train[j]\n",
    "            test=key_test[j]\n",
    "            \n",
    "            ax[1].plot(ES_df[j],'k--',label='E$_{CI}$-E$_{v2RDM}$')\n",
    "            ax[1].plot(range(len(ES_df[j])),len(ES_df[j])*[0],'k-')\n",
    "            ax[1].plot(ES_CI.loc[train]-(ES_ytrain_preddf[j]+ES_rdm.loc[train]),'o',color=colormap[1],label='E$_{CI}$-E$_{DDv2RDM}$ (Train)')\n",
    "            ax[1].plot(ES_CI.loc[test]-(ES_ytest_preddf[j]+ES_rdm.loc[test]),'x',color=colormap[1],label='E$_{CI}$-E$_{DDv2RDM}$ (Test)')\n",
    "        \n",
    "            ax[1].set_xlim(.5,3)\n",
    "            ax[1].legend(loc=2)\n",
    "            ax[1].set_title(f'{i} Excited Spin State')            \n",
    "            ax[1].set_xlabel('Bond Length (Å)')            \n",
    "    # if idx==21:\n",
    "        \n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "    if savefiles==True:\n",
    "        plt.savefig(f'{basis}_bigstack_stacked_{idx}.png',dpi=300,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceb522b-da04-471f-8ddf-c70efd8a7997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot regression parity plots\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "fontsize = 16\n",
    "plt.rcParams.update({'font.size': fontsize})\n",
    "plt.rc('font', size=fontsize)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=fontsize)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=fontsize)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=fontsize)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=fontsize)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=fontsize)    # legend fontsize\n",
    "plt.rc('figure', titlesize=fontsize)  # fontsize of the figure title\n",
    "\n",
    "train_plot=pd.DataFrame([y_train,train_pred],index=['True Train','Predicted Train']).T\n",
    "test_plot=pd.DataFrame([y_test,test_pred],index=['True Test','Predicted Test']).T\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15,8),nrows=1, ncols=2)\n",
    "\n",
    "\n",
    "axes[0].scatter(train_plot['True Train'],train_plot['Predicted Train'],color = colormap[0],edgecolors='k')\n",
    "axes[0].text(train_plot['True Train'].min(),train_plot['True Train'].max()-train_plot['True Train'].quantile(0.5),r\"R$^{2}$=\"+f\"{r2_score(train_plot['True Train'],train_plot['Predicted Train']):.4f}\\nRMSE={mean_squared_error(train_plot['True Train'],train_plot['Predicted Train'],squared=False):.4e}\"+r\" E$_{h}$\")\n",
    "\n",
    "minx=-5e-3\n",
    "maxx=max(train_plot['True Train'])+max(train_plot['True Train'])/10\n",
    "axes[0].set_xlim(minx,maxx)\n",
    "axes[0].set_ylim(minx,maxx)\n",
    "axes[0].set_xticks(axes[0].get_xticks())\n",
    "axes[0].set_yticks(axes[0].get_yticks())\n",
    "axes[0].set_xlabel('True Target Value (E$_{h}$)')\n",
    "axes[0].set_ylabel('Predicted Target Value (E$_{h}$)')    \n",
    "\n",
    "divider = make_axes_locatable(axes[0])\n",
    "axHistx = divider.append_axes(\"top\", 1.2, pad=0.4, sharex=axes[0])\n",
    "axHisty = divider.append_axes(\"right\", 1.2, pad=0.4, sharey=axes[0])\n",
    "\n",
    "\n",
    "# make some labels invisible\n",
    "axHistx.xaxis.set_tick_params(labelbottom=False)\n",
    "axHisty.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "# now determine nice limits by hand:\n",
    "binwidth = 0.01\n",
    "x=train_plot['True Train']\n",
    "y=train_plot['Predicted Train']\n",
    "xymax = max(np.max(np.abs(x)), np.max(np.abs(y)))\n",
    "lim = (int(xymax/binwidth) + 1)*binwidth\n",
    "\n",
    "bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "axHistx.hist(x, bins=bins,color=colormap[0],density=True,edgecolor='k',stacked=True)\n",
    "axHisty.hist(y, bins=bins, orientation='horizontal',color=colormap[0],density=True,edgecolor='k',stacked=True)\n",
    "\n",
    "axHistx.set_ylabel('Probability',fontsize=fontsize-2)\n",
    "\n",
    "axHisty.yaxis.set_label_position(\"right\")\n",
    "# axHisty.yaxis.tick_right()\n",
    "# axHisty.set_ylabel('Probability', rotation=270,labelpad=15)\n",
    "axHisty.set_xlabel('Probability',fontsize=fontsize-2)\n",
    "\n",
    "# the xaxis of axHistx and yaxis of axHisty are shared with axScatter,\n",
    "# thus there is no need to manually adjust the xlim and ylim of these\n",
    "# axis.\n",
    "axHistx.set_title('Train')\n",
    "axHistx.set_yticks(np.linspace(0,70,3))\n",
    "axHisty.set_xticks(np.linspace(0,70,3))\n",
    "\n",
    "\n",
    "\n",
    "# 2\n",
    "axes[1].scatter(test_plot['True Test'],test_plot['Predicted Test'],color = colormap[1],edgecolors='k')\n",
    "axes[1].text(train_plot['True Train'].min(),train_plot['True Train'].max()-train_plot['True Train'].quantile(0.5),r\"R$^{2}$=\"+f\"{r2_score(test_plot['True Test'],test_plot['Predicted Test']):.4f}\\nRMSE={mean_squared_error(test_plot['True Test'],test_plot['Predicted Test'],squared=False):.4e}\"+r\" E$_{h}$\")\n",
    "minx=-5e-3\n",
    "maxx=max(test_plot['True Test'])+max(test_plot['True Test'])/10\n",
    "axes[1].set_xlim(minx,maxx)\n",
    "axes[1].set_ylim(minx,maxx)\n",
    "axes[1].set_xticks(axes[1].get_xticks())\n",
    "axes[1].set_yticks(axes[1].get_yticks())\n",
    "axes[1].set_xlabel('True Target Value (E$_{h}$)')\n",
    "axes[1].set_ylabel('Predicted Target Value (E$_{h}$)')    \n",
    "\n",
    "divider = make_axes_locatable(axes[1])\n",
    "axHistx = divider.append_axes(\"top\", 1.2, pad=0.4, sharex=axes[1])\n",
    "axHisty = divider.append_axes(\"right\", 1.2, pad=0.4, sharey=axes[1])\n",
    "\n",
    "\n",
    "# make some labels invisible\n",
    "axHistx.xaxis.set_tick_params(labelbottom=False)\n",
    "axHisty.yaxis.set_tick_params(labelleft=False)\n",
    "\n",
    "# now determine nice limits by hand:\n",
    "x=test_plot['True Test']\n",
    "y=test_plot['Predicted Test']\n",
    "binwidth = 0.01\n",
    "xymax = max(np.max(np.abs(x)), np.max(np.abs(y)))\n",
    "lim = (int(xymax/binwidth) + 1)*binwidth\n",
    "\n",
    "bins = np.arange(-lim, lim + binwidth, binwidth)\n",
    "axHistx.hist(x, bins=bins,color=colormap[1],density=True,edgecolor='k',stacked=True)\n",
    "axHisty.hist(y, bins=bins, orientation='horizontal',color=colormap[1],density=True,edgecolor='k',stacked=True)\n",
    "\n",
    "axHistx.set_ylabel('Probability',fontsize=fontsize-2)\n",
    "axHistx.set_title('Test')\n",
    "axHisty.yaxis.set_label_position(\"right\")\n",
    "# axHisty.yaxis.tick_right()\n",
    "# axHisty.set_ylabel('Probability', rotation=270,labelpad=15)\n",
    "axHisty.set_xlabel('Probability',fontsize=fontsize-2)\n",
    "\n",
    "# the xaxis of axHistx and yaxis of axHisty are shared with axScatter,\n",
    "# thus there is no need to manually adjust the xlim and ylim of these\n",
    "# axis.\n",
    "\n",
    "axHistx.set_yticks(np.linspace(0,70,3))\n",
    "axHisty.set_xticks(np.linspace(0,70,3))\n",
    "plt.tight_layout(pad=1, w_pad=1, h_pad=1.0)\n",
    "if savefiles==True:\n",
    "    plt.savefig(f'{basis}_bigstack_error.png',dpi=300,bbox_inches='tight')    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558dca05-4802-4f2e-8a8c-a850e9b8f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab spins\n",
    "s2_dict={sp:{sy:{bs:gen_df(glob(f'./{sp}/v2rdm_ontop_fci_eval_t1t2/{sy}/{bs}/*')[0]).loc['v2RDM@S2'].to_numpy() for bs in basissets} for sy in systems} for sp in spins}\n",
    "alpha_dict={sp:{sy:{bs:gen_df(glob(f'./{sp}/v2rdm_ontop_fci_eval_t1t2/{sy}/{bs}/*')[0]).loc['v2RDM@Nalpha'].to_numpy() for bs in basissets} for sy in systems} for sp in spins}\n",
    "beta_dict={sp:{sy:{bs:gen_df(glob(f'./{sp}/v2rdm_ontop_fci_eval_t1t2/{sy}/{bs}/*')[0]).loc['v2RDM@Nbeta'].to_numpy() for bs in basissets} for sy in systems} for sp in spins}\n",
    "\n",
    "gs_df=[]\n",
    "for st,sy,bs in tqdm(groundstates, desc='Data', position=0, leave=True):\n",
    "    gs_df.append((st,sy,bs,0.5*int(alpha_dict[st][sy][bs]-beta_dict[st][sy][bs])))\n",
    "gs_df=pd.DataFrame(gs_df,columns=['spin_dir','system','basis','S'])\n",
    "\n",
    "\n",
    "es_df=[]\n",
    "for st,sy,bs in tqdm(excitedstates, desc='Data', position=0, leave=True):\n",
    "    es_df.append((st,sy,bs,0.5*int(alpha_dict[st][sy][bs]-beta_dict[st][sy][bs])))\n",
    "es_df=pd.DataFrame(es_df,columns=['spin_dir','system','basis','S'])\n",
    "\n",
    "es_df['2S+1']=2*es_df['S']+1\n",
    "gs_df['2S+1']=2*gs_df['S']+1\n",
    "sp_df=pd.concat([gs_df,es_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3991b1f3-f85c-4dd5-9950-973efe0036b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spread of the target values for the ground and excited state molecules\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5),sharey=True)\n",
    "ax1.plot(GS_df.T.columns,GS_df.T.max(),'-x',label='Max',color=colormap[0])\n",
    "ax1.plot(GS_df.T.columns,GS_df.T.mean(),'-',label='Mean',color=colormap[0])\n",
    "ax1.plot(GS_df.T.columns,GS_df.T.min(),'-^',label='Min',color=colormap[0])\n",
    "ax1.fill_between(GS_df.T.columns,GS_df.T.min(),GS_df.T.mean(),alpha=0.4,color=colormap[0])\n",
    "ax1.fill_between(GS_df.T.columns,GS_df.T.mean(),GS_df.T.max(),alpha=0.4,color=colormap[0])\n",
    "ax1.legend()\n",
    "ax1.set_xticks(np.linspace(0.5,4,15))\n",
    "ax1.set_xlim(0.5,3)\n",
    "ax1.set_ylim(-0.001,0.10)\n",
    "\n",
    "ax1.set_xlabel('Bond Length ($\\AA$)')\n",
    "ax1.set_ylabel('E$_{CI}$-E$_{v2RDM}$ (E$_{h}$)')\n",
    "ax1.set_title('Ground Spin States')\n",
    "\n",
    "ax2.plot(ES_df.T.columns,ES_df.T.max(),'-x',label='Max',color=colormap[1])\n",
    "ax2.plot(ES_df.T.columns,ES_df.T.mean(),'-',label='Mean',color=colormap[1])\n",
    "ax2.plot(ES_df.T.columns,ES_df.T.min(),'-^',label='Min',color=colormap[1])\n",
    "ax2.fill_between(ES_df.T.columns,ES_df.T.min(),ES_df.T.mean(),alpha=0.4,color=colormap[1])\n",
    "ax2.fill_between(ES_df.T.columns,ES_df.T.max(),ES_df.T.mean(),alpha=0.4,color=colormap[1])\n",
    "ax2.set_xticks(np.linspace(0.5,4,15))\n",
    "ax2.set_xlim(0.5,3)\n",
    "ax2.set_xlabel('Bond Length ($\\AA$)')\n",
    "ax2.set_title('Excited Spin States')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "if savefiles==True:\n",
    "    plt.savefig(f'{basis}_GS_ES_spreads.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2626d8-7db1-44c4-b14c-fc057d9894b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "statdf=pd.DataFrame(columns=system_dict.keys(),index=['Train R2','Test R2','Train MAPE','Test MAPE','Train RMSE','Test RMSE','State','system'])\n",
    "survived_ES=set(statdf.columns).intersection(set([sy+'_'+st for st,sy,bs in excitedstates if bs==basis]))\n",
    "survived_GS=set(statdf.columns).intersection(set([sy+'_'+st for st,sy,bs in groundstates if bs==basis]))\n",
    "\n",
    "for i in system_dict.keys():\n",
    "    statdf[i].loc['system']=i.split('_')[0]\n",
    "    statdf[i].loc['Train R2']=r2_score(ytraindf[i].dropna(),ytrain_preddf[i].dropna())\n",
    "    statdf[i].loc['Test R2']=r2_score(ytestdf[i].dropna(),ytest_preddf[i].dropna())\n",
    "    statdf[i].loc['Train MAPE']=mean_absolute_percentage_error(ytraindf[i].dropna(),ytrain_preddf[i].dropna())\n",
    "    statdf[i].loc['Test MAPE']=mean_absolute_percentage_error(ytestdf[i].dropna(),ytest_preddf[i].dropna())\n",
    "    statdf[i].loc['Train RMSE']=mean_squared_error(ytraindf[i].dropna(),ytrain_preddf[i].dropna(), squared=False)\n",
    "    statdf[i].loc['Test RMSE']=mean_squared_error(ytestdf[i].dropna(),ytest_preddf[i].dropna(), squared=False)\n",
    "for i in list(survived_ES):\n",
    "    statdf[i].loc['State']='ES'\n",
    "for i in list(survived_GS): \n",
    "    statdf[i].loc['State']='GS'  \n",
    "\n",
    "if savefiles==True:    \n",
    "    statdf.to_excel(f'{basis}_stats.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d51057-f21f-4ba4-abdc-7a31878aafb3",
   "metadata": {},
   "source": [
    "# SHapley Additive exPlanation (SHAP) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818b475-a1d8-4371-b613-bd6a206195e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the SHAP values\n",
    "cc_xtestdf=pd.concat([X for k,(X,y) in system_dict.items()],axis=0)\n",
    "# .iloc[CC_singlet_doublet_idx]\n",
    "cc_xtest=pd.DataFrame(scaler.transform(cc_xtestdf),columns=cc_xtestdf.columns,index=cc_xtestdf.index)\n",
    "explainer = shap.Explainer(model.predict, cc_xtest)\n",
    "shap_values = explainer(cc_xtest)\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "color_map=sns.color_palette('rocket',6)\n",
    "fontsize = 16\n",
    "upd_feat_dict={'entropy(D1a)':'entropy(${}^1\\mathbf{D}_{\\\\alpha}$)', 'entropy(D1b)':'entropy(${}^1\\mathbf{D}_{\\\\beta}$)', 'entropy(Q1a)':'entropy(${}^1\\mathbf{Q}_{\\\\alpha}$)', 'entropy(Q1b)':'entropy(${}^1\\mathbf{Q}_{\\\\beta}$)', 'entropy(D2aa)':'entropy(${}^2\\mathbf{D}_{\\\\alpha \\\\alpha}$)', 'entropy(D2bb)':'entropy(${}^2\\mathbf{D}_{\\\\beta \\\\beta}$)', 'entropy(D2ab)':'entropy(${}^2\\mathbf{D}_{\\\\alpha \\\\beta}$)', 'entropy(Q2aa)':'entropy(${}^2\\mathbf{Q}_{\\\\alpha \\\\alpha}$)', 'entropy(Q2bb)':'entropy(${}^2\\mathbf{Q}_{\\\\beta \\\\beta}$)', 'entropy(Q2ab)':'entropy(${}^2\\mathbf{Q}_{\\\\alpha \\\\beta}$)', 'entropy(G2ab)':'entropy(${}^2\\mathbf{G}_{\\\\alpha \\\\beta}$)', 'entropy(G2ba)':'entropy(${}^2\\mathbf{G}_{\\\\beta \\\\alpha}$)', 'entropy(G2aa/bb)':'entropy(${}^2\\mathbf{G}_{\\\\alpha\\\\alpha / \\\\beta\\\\beta}$)', 'Violation%(T1)':'Percent Violation T1', 'Violation%(T2)':'Percent Violation T2', 'AveViolation(T1)':'Average Violation T1', 'AveViolation(T2)':'Average Violation T2', 'RMSViolation(T1)':'RMS Violation T1', 'RMSViolation(T2)':'RMS Violation T2', 'VarViolation(T1)':'Variance Violation T1', 'VarViolation(T2)':'Variance Violation T2', '||del2(aa)||^2':'$|| ^{2}{\\\\Delta}_{\\\\alpha \\\\alpha}||^{2}$', '||del2(bb)||^2':'$|| ^{2}{\\\\Delta}_{\\\\beta \\\\beta}||^{2}$', '||del2(ab)||^2':'$|| ^{2}{\\\\Delta}_{\\\\alpha \\\\beta}||^{2}$', 'Tr[del2(aa)]':'Tr$(^{2}{\\\\Delta}_{\\\\alpha \\\\alpha})$', 'Tr[del2(bb)]':'Tr$(^{2}{\\\\Delta}_{\\\\beta \\\\beta})$', 'Tr[del2(ab)]':'Tr$(^{2}{\\\\Delta}_{\\\\alpha \\\\beta})$'}\n",
    "plt.rcParams.update({'font.size': fontsize})\n",
    "plt.rc('font', size=fontsize)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=fontsize)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=fontsize)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=fontsize)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=fontsize)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=fontsize)    # legend fontsize\n",
    "plt.rc('figure', titlesize=fontsize)  # fontsize of the figure title\n",
    "\n",
    "df=pd.DataFrame(dict(zip([upd_feat_dict[i.replace('v2RDM@','')] for i in shap_values.feature_names],shap_values.abs.values.mean(axis=0).reshape(-1,))).items())\n",
    "df.columns=['Features','|SHAP|']\n",
    "df=df.sort_values('|SHAP|')\n",
    "\n",
    "ax=df.plot.barh(x='Features',y='|SHAP|',color=color_map[3], figsize=(8, 10),legend=False)\n",
    "ax.bar_label(ax.containers[0], fmt='%.4e',fontsize=12,padding=1)\n",
    "plt.xticks(np.linspace(0,3e-3,4))\n",
    "plt.xlim(0,3e-3)\n",
    "plt.xlabel('mean(|SHAP value|)')\n",
    "plt.tight_layout()\n",
    "if savefiles==True:\n",
    "    plt.savefig(f'{basis}_barall.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "if savefiles==True:\n",
    "    df.to_excel(f'{basis}_SHAP.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
